### 1.5 Model Selection
#### Simple model selection
This process consists of the following phases:
1. Split the available data into three sets:
   - Train (e.g. $60\%$)
   - Validation (e.g. $20\%$)
   - Test (e.g. $20\%$)
1. Train different models using the _train set_
1. Evaluate the trained models using the _validation set_ and pick the model with best performance
1. Test the chosen model with the _test set_ and check that the picked model was not particularly lucky with _validation set_.
   - Additionally, we can combine the _train_ and _validation_ set into a bigger new _train set_ to test again the picked model and not throw away the knowledge that validation set may provide to the model. Then, check again using the _test set_, and the performance of the model should improve.

#### Model selection using $k$-fold cross-validation 
**Notes in this section were made from comments in the video and reading Wikipedia:**
Most of the cases what is implemented in practice is a little bit different approach extended from the previous one to address issues like overfitting and bias of the model during the validation (i.e. running the model against the _validation set_).

1. Split the available data into two sets:
   - Train (e.g. $80\%$)
   - Test (e.g. $20\%$)
1. Split the _train set_ into $k$ (e.g. $k=5$) subsets, also know as _folds_. 
1. For every model to evaluate: 
   - iterativelly pick a _fold_ as _validation set_, 
   - train the model using the remaining folds combined into a single set, and 
   - evaluate the model agains the picked _fold_. 
   - Then, combine the obtained error in each iteration for each model and pick the model with best performance (i.e. the one with lower combined error). 
   
   This is what is called _cross-validation_. 

    >Check the  cross-validation in the following pseudo-code (let `x_train[i]` and `y_train[i]` denote the input and target in the $i$-th fold):
    >```python
    >error = 0
    >for i in [1..k]
    >   # pick i-th fold as validation_set
    >   x_val = x_train[i]
    >   y_val = y_train[i]
    >
    >   # combine remaining folds into a single set  
    >   x_in = join(x_train[j] for j in [1..i-1,i+1..k])
    >   y_in = join(y_train[j] for j in [1..i-1,i+1..k])
    >
    >   # train the model
    >   model_train(x_in, y_in)
    >
    >   # evaluate the model 
    >   y_pred = model_predict(x_val)
    >
    >   # combine errors in different folds
    >   error += compute_error(y_pred, y_val)
    >
    ># average error among the folds
    >error = error/k
    >```
1. Pick the model with lower error and train the model again using the whole _train set_ (i.e. combining all the folds)
1. Test the chosen model with the _test set_ and check that the picked model is actually good.